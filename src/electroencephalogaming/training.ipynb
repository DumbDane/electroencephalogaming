{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adapted from Pedro L. C. Rodrigues, Sylvain Chevallier\n",
    "#\n",
    "# https://github.com/plcrodrigues/Workshop-MOABB-BCI-Graz-2019\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from mne.decoding import CSP\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import moabb\n",
    "from moabb.evaluations import WithinSessionEvaluation\n",
    "from moabb.paradigms import MotorImagery\n",
    "import mne\n",
    "\n",
    "\n",
    "moabb.set_log_level(\"info\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datacleaning\n",
    "Our data comes in raw, unshaped and forward filled.<br>\n",
    "First we find individual trials, then reshape and possibly further transform the data before we can use it to fit a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('eeg_data/p2s1t18_b.csv').dropna().reset_index(drop=True)\n",
    "df = df[(df['markers'] != 86) & (df['markers'] != 99)]\n",
    "trial_indices = df[(df['markers'] == df['direction']) & (df.shift()['markers'] != df['direction'])].index\n",
    "trial_indices = trial_indices.append(df.iloc[-1:].index)\n",
    "trial_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.empty((len(trial_indices-1), ))\n",
    "for i, j in zip(range(len(trial_indices)-1), range(1, len(trial_indices))):\n",
    "    arr.vstack(df.iloc[trial_indices[i]:trial_indices[j]][df['markers'] == 4])\n",
    "\n",
    "data = pd.MultiIndex.from_product([arr])\n",
    "data\n",
    "# trial_indices = trial_indices.append(df.iloc[-1:].index)\n",
    "# df.iloc[-1:].index\n",
    "# trial_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating Dataset\n",
    "\n",
    "The first thing to do is to instantiate the dataset that we want to analyze.\n",
    "MOABB has a list of many different datasets, each one containing all the\n",
    "necessary information for describing them, such as the number of subjects,\n",
    "size of trials, names of classes, etc.\n",
    "\n",
    "The dataset class has methods for:\n",
    "\n",
    "- downloading its files from some online source (e.g. Zenodo)\n",
    "- importing the data from the files in whatever extension they might be\n",
    "  (like .mat, .gdf, etc.) and instantiate a Raw object from the MNE package\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('eeg_data/1-4.csv')\n",
    "datafile = Path('/Volumes/EEGTRANSFER/melodies-recon/EEG/day1/ses-flute/eeg/sub-aaa_ses-flute_task-Default_run-001_eeg.xdf')\n",
    "df = pd.read_csv(path).dropna()\n",
    "df = df[df['markers'] == 4]\n",
    "df.pop('markers')\n",
    "labels = df.pop('direction')\n",
    "df.rename(columns={'Unnamed: 0':'epoch'}, inplace=True)\n",
    "# ts = df.pop('Unnamed: 0')\n",
    "info = mne.create_info(ch_names=df.columns.tolist(), sfreq=500)\n",
    "# data = mne.io.RawArray(df.dropna().multiply(1e-9).T, info)\n",
    "dataset = mne.io.RawArray(df.dropna().T, info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Paradigm\n",
    "\n",
    "Once we have instantiated a dataset, we have to choose a paradigm. This\n",
    "object is responsible for filtering the data, epoching it, and extracting\n",
    "the labels for each epoch. Note that each dataset comes with the names of\n",
    "the paradigms to which it might be associated. It would not make sense to\n",
    "process a P300 dataset with a MI paradigm object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paradigm = MotorImagery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, labels, meta = paradigm.get_data(dataset=dataset, subjects=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "\n",
    "Our goal is to evaluate the performance of a given classification pipeline\n",
    "(or several of them) when it is applied to the epochs from the previously\n",
    "chosen dataset. We will consider a very simple classification pipeline in\n",
    "which the dimension of the epochs are reduced via a CSP step and then\n",
    "classified via a linear discriminant analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(CSP(), LDA())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "To evaluate the score of this pipeline, we use the `evaluation` class. When\n",
    "instantiating it, we say which paradigm we want to consider, a list with the\n",
    "datasets to analyze, and whether the scores should be recalculated each time\n",
    "we run the evaluation or if MOABB should create a cache file.\n",
    "\n",
    "Note that there are different ways of evaluating a classifier; in this\n",
    "example, we choose `WithinSessionEvaluation`, which consists of doing a\n",
    "cross-validation procedure where the training and testing partitions are from\n",
    "the same recording session of the dataset. We could have used\n",
    "`CrossSessionEvaluation`, which takes all but one session as training\n",
    "partition and the remaining one as testing partition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation = WithinSessionEvaluation(\n",
    "#     paradigm=paradigm,\n",
    "#     datasets=[dataset],\n",
    "#     overwrite=True,\n",
    "#     hdf5_path=None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.to_numpy().res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSP().fit(X.T, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = evaluation.process({\"csp+lda\": pipeline})\n",
    "clf = pipeline.fit(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([X[123]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipeline, X, labels, cv=5, scoring=\"roc_auc_ovr\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results\n",
    "\n",
    "We create a figure with the seaborn package comparing the classification\n",
    "score for each subject on each session. Note that the 'subject' field from\n",
    "the `results` is given in terms of integers, but seaborn accepts only\n",
    "strings for its labeling. This is why we create the field 'subj'.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
