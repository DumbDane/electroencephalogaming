{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Motor imagery decoding from EEG data using the Common Spatial Pattern (CSP)\n",
    "\n",
    "Decoding of motor imagery applied to EEG data decomposed using CSP. A\n",
    "classifier is then applied to features extracted on CSP-filtered signals.\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Common_spatial_pattern and\n",
    ":footcite:`Koles1991`. The EEGBCI dataset is documented in\n",
    ":footcite:`SchalkEtAl2004` and is available at PhysioNet\n",
    ":footcite:`GoldbergerEtAl2000`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Martin Billinger <martin.billinger@tugraz.at>\n",
    "#\n",
    "# License: BSD-3-Clause\n",
    "# Copyright the MNE-Python contributors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer, confusion_matrix\n",
    "\n",
    "from mne import Epochs, pick_types, find_events\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP, UnsupervisedSpatialFilter, Vectorizer, Scaler\n",
    "from mne.io import concatenate_raws, read_raw_fif, read_raw_edf\n",
    "\n",
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# # Set parameters and read data\n",
    "\n",
    "# avoid classification of evoked responses by using epochs that start 1s after\n",
    "# cue onset.\n",
    "tmin, tmax = -1.0, 4\n",
    "\n",
    "subject = 1\n",
    "runs = [6, 10, 14]  # motor imagery: hands vs feet\n",
    "raw_fnames = eegbci.load_data(subject, runs)\n",
    "raw = concatenate_raws([read_raw_edf(f, preload=True) for f in raw_fnames])\n",
    "raw.annotations.rename(dict(T1=\"hands\", T2=\"feet\"))\n",
    "eegbci.standardize(raw)  # set channel names\n",
    "\n",
    "subject = \"chris\"\n",
    "subject = \"laurids\"\n",
    "raw_fnames = glob(f\"data/scratch/{subject}/*_b*/*raw.fif\")\n",
    "raw = concatenate_raws([read_raw_fif(f, preload=True) for f in raw_fnames])\n",
    "\n",
    "montage = make_standard_montage(\"standard_1005\")\n",
    "raw.set_montage(montage)\n",
    "raw.set_eeg_reference(projection=True)\n",
    "raw.apply_proj()\n",
    "\n",
    "# Apply band-pass filter\n",
    "raw.filter(7.0, 30.0, fir_design=\"firwin\", skip_by_annotation=\"edge\")\n",
    "\n",
    "picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")\n",
    "events = find_events(raw, stim_channel='trigger', verbose=True)\n",
    "classes = [90, 180, 270]\n",
    "\n",
    "# Read epochs (train will be done only between 1 and 2s)\n",
    "# Testing will be done with a running classifier\n",
    "epochs = Epochs(\n",
    "    raw,\n",
    "    events=events,\n",
    "    event_id=classes,\n",
    "    tmin=tmin,\n",
    "    tmax=tmax,\n",
    "    proj=True,\n",
    "    picks=picks,\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    ")\n",
    "epochs_train = epochs.copy().crop(tmin=2, tmax=2.5)\n",
    "labels = epochs.events[:, -1]\n",
    "\n",
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification with linear discrimant analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pink = sns.light_palette('#69B45B', as_cmap=True)\n",
    "savefigs = False\n",
    "font = {\n",
    "    'size': 12\n",
    "}\n",
    "\n",
    "def plot_cf(cf: np.ndarray[np.ndarray[int]], title : str, classes):\n",
    "    label_convert = {90 : 'Right', 180 : 'Feet', 270 : 'Left'}\n",
    "    group_names = [x for xs in \n",
    "                   [[\"True \" + label_convert[c] if c == i else \"False \" + label_convert[c] for c in classes] for i in classes] \n",
    "                   for x in xs]\n",
    "    #creating labels to add to the heatmap\n",
    "    # group_names = ['True Pop','False Rap','False Rb',\n",
    "    #                'False Pop', 'True Rap', 'False Rb', \n",
    "    #                'False Pop', 'False Rap', 'True Rb']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in cf.flatten()]\n",
    "    labels = [f'{v1}\\n{v2}' for v1, v2 in\n",
    "            zip(group_names,group_counts)]\n",
    "    labels = np.asarray(labels).reshape(len(classes),len(classes))\n",
    "    print(labels)\n",
    "\n",
    "    #creating the heatmap and adding titels\n",
    "    f, ax = plt.subplots(figsize=(10,7))\n",
    "    ticks = [label_convert[c] for c in classes]\n",
    "    sns.heatmap(cf, annot=labels, fmt='', cmap= pink, xticklabels=ticks, yticklabels=ticks, ax=ax)\n",
    "\n",
    "    ax.set_xlabel('Predicted', fontdict=font)\n",
    "    ax.set_ylabel('Actual', fontdict=font)\n",
    "\n",
    "    plt.suptitle(f'Song genre prediction {title}', fontsize=18, x=0.45)\n",
    "    plt.title('Heatmap of the confusion matrix', fontsize=12)\n",
    "\n",
    "    if savefigs:\n",
    "        plt.savefig(f'figs/figure_{title}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes, pred_classes = [], []\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    # print(classification_report(y_true, y_pred)) # print classification report\n",
    "    true_classes.extend(y_true)\n",
    "    pred_classes.extend(y_pred)\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score\n",
    "    \n",
    "\n",
    "\n",
    "# Define a monte-carlo cross-validation generator (reduce variance):\n",
    "scores = []\n",
    "# epochs_data = epochs.get_data(copy=False)\n",
    "epochs_data_train = epochs_train.get_data(copy=False)\n",
    "cv = ShuffleSplit(10, test_size=0.2, random_state=42)\n",
    "# cv_split = cv.split(epochs_data_train)\n",
    "\n",
    "# Preprocessing\n",
    "scaler = Scaler(epochs.info)\n",
    "csp = CSP(n_components=8, reg=None, norm_trace=False, log=True)\n",
    "pca = UnsupervisedSpatialFilter(PCA(), average=True)\n",
    "vec = Vectorizer()\n",
    "\n",
    "# Assemble a classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "svc = SVC(kernel = \"linear\")\n",
    "\n",
    "\n",
    "# Use scikit-learn Pipeline with cross_val_score function\n",
    "# clf = Pipeline([(\"PCA\", pca), (\"CSP\", csp), (\"LDA\", lda)])\n",
    "# clf = Pipeline([(\"Scaler\", scaler), (\"PCA\", pca), (\"Vectorizer\", vec), (\"SVM\", svc)])\n",
    "clf = Pipeline([(\"Scaler\", scaler), (\"PCA\", pca), (\"Vectorizer\", vec), (\"LDA\", lda)])\n",
    "\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=None, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "# scores = cross_val_score(clf, epochs_data_train, labels, cv=cv, n_jobs=None)\n",
    "\n",
    "# Printing the results\n",
    "# class_balance = np.mean(labels == labels[0])\n",
    "# class_balance = max(class_balance, 1.0 - class_balance)\n",
    "# print(f\"Classification accuracy: {np.mean(scores)} / Chance level: {class_balance}\")\n",
    "\n",
    "# plot CSP patterns estimated on full data for visualization\n",
    "# csp.fit_transform(epochs_data, labels)\n",
    "\n",
    "# csp.plot_patterns(epochs.info, ch_type=\"eeg\", units=\"Patterns (AU)\", size=1.5)\n",
    "# Printing the results\n",
    "\n",
    "\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = min(class_balance, 1.0 - class_balance)\n",
    "print(classification_report(pred_classes, true_classes)) # print classification report\n",
    "print(\"=\"*20)\n",
    "print(f\"Classification accuracy: {np.mean(scores)} / Chance level: {class_balance}\")\n",
    "plot_cf(confusion_matrix(true_classes, pred_classes), \"test\", classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at performance over time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(classes) < 3, \"Can't do CSP on more than 2 classes\"\n",
    "cv_split = cv.split(epochs_data_train)\n",
    "sfreq = raw.info[\"sfreq\"]\n",
    "w_length = int(sfreq * 0.5)  # running classifier: window length\n",
    "w_step = int(sfreq * 0.1)  # running classifier: window step size\n",
    "w_start = np.arange(0, epochs_data.shape[2] - w_length, w_step)\n",
    "\n",
    "scores_windows = []\n",
    "\n",
    "minipca = Pipeline([(\"PCA\", pca), (\"Vectorizer\", vec)])\n",
    "minicsp = Pipeline([(\"PCA\", pca), (\"CSP\", csp)])\n",
    "\n",
    "for train_idx, test_idx in cv_split:\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    X_train = minicsp.fit_transform(epochs_data_train[train_idx], y_train)\n",
    "    X_test = minicsp.transform(epochs_data_train[test_idx])\n",
    "    # fit classifier\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    # running classifier: test classifier on sliding window\n",
    "    score_this_window = []\n",
    "    for n in w_start:\n",
    "        X_test = minicsp.transform(epochs_data[test_idx][:, :, n : (n + w_length)])\n",
    "        score_this_window.append(svc.score(X_test, y_test))\n",
    "\n",
    "    scores_windows.append(score_this_window)\n",
    "\n",
    "# Plot scores over time\n",
    "w_times = (w_start + w_length / 2.0) / sfreq + epochs.tmin\n",
    "plt.figure()\n",
    "plt.plot(w_times, np.mean(scores_windows, 0), label=\"Score\")\n",
    "plt.axvline(0, linestyle=\"--\", color=\"k\", label=\"Onset\")\n",
    "plt.axhline(0.5, linestyle=\"-\", color=\"k\", label=\"Chance\")\n",
    "plt.ylim(bottom=0, top=1)\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"classification accuracy\")\n",
    "plt.title(\"Classification score over time\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    ".. footbibliography::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
