---
Title: MOABB, trustworthy algorithm benchmarking for BCIs
Authors:
  - Vinay Jayaram
  - Alexandre Barachant
DOI: http://dx.doi.org/10.1088/1741-2552/aadea0
link: https://iopscience.iop.org/article/10.1088/1741-2552/aadea0
tags:
  - EEG
Read: false
---

# MOABB, trustworthy algorithm benchmarking for BCIs

### Abstract
>[!quote] _Objective_. Brain–computer interface (BCI) algorithm development has long been hampered by two major issues: small sample sets and a lack of reproducibility. We offer a solution to both of these problems via a software suite that streamlines both the issues of finding and preprocessing data in a reliable manner, as well as that of using a consistent interface for machine learning methods. _Approach_. By building on recent advances in software for signal analysis implemented in the MNE toolkit, and the unified framework for machine learning offered by the scikit-learn project, we offer a system that can improve BCI algorithm development. This system is fully open-source under the BSD licence and available at [https://github.com/NeuroTechX/moabb](https://github.com/NeuroTechX/moabb). _Main results_. We analyze a set of state-of-the-art decoding algorithms across 12 open access datasets, including over 250 subjects. Our results show that even for the best methods, there are datasets which do not show significant improvements, and further that many previously validated methods do not generalize well outside the datasets they were tested on. _Significance_. Our analysis confirms that BCI algorithms validated on single datasets are not representative, highlighting the need for more robust validation in the machine learning for BCIs community.

