
Brain-computer Interfaces open up new possibilities for digital interaction in games.
Prior research, Brain Invaders, used P300 stimuli to play a video game replica of the classic game Space Invaders. The downside of their project was that the game had to be recreated with the EEG in mind. We believe using motor imagery instead will allow for a user to play various games, independent of whether they contain P300 stimuli.
We would like to experiment with different uses of datasets, pinning classification models against each other in various ways, to see their difference in performance. 
We would like to see the effects of training classifiers on different types of dataset compositions, e.g. training exclusively on external data versus data from participants. Also how the intersection of these might affect training cost.
We hope to find that external data can be used with minimal personal data to lower training cost and bar of entry for an end user, thus making EEGs available for a broader audience.



(ONLY FOR PAOLOS EYES NOT THE PROBLEM STATEMENT)
Different experiments would be: 
* seeing if classifiers trained on exclusively external EEG data can can be used by us 
* Seeing if a classifier trained on data from one of us performs better/worse on the other, does one of our brains generalise better?
* Seeing if we can use the personal training data to tune the classifier trained on external data, will this cut training costs?
